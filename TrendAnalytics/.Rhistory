library (twitteR)
library (openssl)
library (NLP)
library (tm)
library (stringr)
library (dplyr)
library (ggplot2)
library(wordcloud)
library (rtweet)
library (tidytext)
library (tidyverse)
CONSUMER_SECRET <- "ZdGZi9aGG0VbOj1cdWXk6PzgQzmpAq7s3z9LsLUby2vGV7iHD7"
CONSUMER_KEY <- "ll18xpJcySQHXceY9oXO1cuZZ"
ACCESS_TOKEN <- "1533805509161017345-nT2JxCrqKUIplJXSrrdXDRoyG5grER"
ACCESS_SECRET <- "7EXHyEA844xyeCNfWgMd5ffoZGjfaWMmw1jw92VFSKAVN"
setup_twitter_oauth(
consumer_key = CONSUMER_KEY,
consumer_secret = CONSUMER_SECRET,
access_token = ACCESS_TOKEN,
access_secret = ACCESS_SECRET
)
trendingTweets = searchTwitter("#ResidentEvil4Remake -filter:retweets",
n =1000, lang = "en",
since = "2022-06-01",
until = "2022-06-18",
retryOnRateLimit = 120)
str (trendingTweets[[1]])
#perform a quick clean up
trendingTweets.df = twListToDF(trendingTweets)
trendingTweets.df$text <- sapply(trendingTweets.df$text,function(x) iconv(enc2utf8(x), sub="byte"))
class (trendingTweets.df)
names(trendingTweets.df)
head(trendingTweets.df$text)
head(trendingTweets.df$text)
#remove emoji
nohandles <- str_replace_all(trendingTweets.df$text, "@\\w+", " ")
nohandles$cleanedText <- gsub("http.*", " ", nohandles)
nohandles$cleanedText <- gsub("https.*", " ", nohandles$cleanedText )
head(nohandles$cleanedText) #dont include
nohandles$cleanedText <- str_replace_all(nohandles$cleanedText, "[^[:alnum:]]", " ")
nohandles$cleanedText <-  str_replace_all(nohandles$cleanedText,"[[^a-zA-Z0-9]]", " ")
head(nohandles$cleanedText)
#gettiing the names to be place in vectors
namesCorpus <- Corpus(VectorSource(trendingTweets.df$screenName))
class(trendingTweets.df$screenName)
str (namesCorpus)
class (namesCorpus)
pal <- brewer.pal (8, "Dark2")
pal <- pal[-(1:4)]
set.seed(42)
par (mar = c (0,0,0,0), mfrow = c(1,1))
wordcloud(words = namesCorpus, scale = c(3,0,5),
max.words = 300,
random.order = FALSE,
rot.per = 0.35,
use.r.layout = TRUE,
colors = pal,
)
set.seed(123)
par (mar = c (0,0,0,0), mfrow = c(1,1))
wordcloud(words = namesCorpus, scale = c(3,0,5),
max.words = 300,
random.order = FALSE,
rot.per = 0.35,
use.r.layout = TRUE,
colors = pal,
)
#install.packages("tm")
library(tm)
############################################################################
# Basic Analytics with R
# Description  :   Connect to Twitter app and perform trend analysis using
#                  different visualizations
# Note         :   Your results may be different than the ones discussed
#                  in the chapter due to dyanmic nature of Twitter
############################################################################
#install.packages("tm")
library(tm)
#install.packages("ggmap")
library(ggmap)
library(ggplot2)
library(twitteR)
library(stringr)
# install.packages("wordcloud")
library(wordcloud)
# set the credentials (just in case)
CONSUMER_SECRET <- "ZdGZi9aGG0VbOj1cdWXk6PzgQzmpAq7s3z9LsLUby2vGV7iHD7"
CONSUMER_KEY <- "ll18xpJcySQHXceY9oXO1cuZZ"
ACCESS_SECRET <- "7EXHyEA844xyeCNfWgMd5ffoZGjfaWMmw1jw92VFSKAVN"
ACCESS_TOKEN <- "1533805509161017345-nT2JxCrqKUIplJXSrrdXDRoyG5grER"
# plot by source
# encode tweet source as iPhone, iPad, Android or Web
# gsub (global substitute): Replace 1st arg with 2nd arg in 3rd arg string
encodeSource <- function(x) {
if(grepl(">Twitter for iPhone</a>", x)){
"iphone"
}else if(grepl(">Twitter for iPad</a>", x)){
"ipad"
}else if(grepl(">Twitter for Android</a>", x)){
"android"
} else if(grepl(">Twitter Web Client</a>", x)){
"Web"
} else if(grepl(">Twitter for Windows Phone</a>", x)){
"windows phone"
}else if(grepl(">dlvr.it</a>", x)){
"dlvr.it"
}else if(grepl(">IFTTT</a>", x)){
"ifttt"
}else if(grepl(">EarthquakeTrack.com</a>", x)){
"earthquaketrack"
}else if(grepl(">Did You Feel It</a>", x)){
"did_you_feel_it"
}else if(grepl(">Earthquake Mobile</a>", x)){
"earthquake_mobile"
}else if(grepl(">Facebook</a>", x)){  #This looks unreliable...
"facebook"
}else {
"others"
}
}
# connect to twitter app
setup_twitter_oauth(consumer_key = CONSUMER_KEY,
consumer_secret = CONSUMER_SECRET,
access_token = ACCESS_TOKEN,
access_secret = ACCESS_SECRET)
# extract tweets based on a search term
searchTerm <- "#ResidentEvil4Remake"
trendingTweets = searchTwitter(searchTerm,n=2000,lang = "en")
#even with lang option, mapCountry gives an error... due to emoji?
class(trendingTweets)
head(trendingTweets)
str(trendingTweets[[1]])
# perform a quick cleanup/transformation
trendingTweets.df = twListToDF(trendingTweets)
View(trendingTweets.df)
class(trendingTweets.df)
names(trendingTweets.df)
head(trendingTweets.df)
head(trendingTweets.df$text)
#trendingTweets.df$text <- sapply(trendingTweets.df$text,function(x) iconv(x,to='UTF-8')) #Removes some (unicode?) values in text field
trendingTweets.df$text <- sapply(trendingTweets.df$text,function(x) iconv(enc2utf8(x), sub="byte"))  #this works fine!!
head(trendingTweets.df$text)
head(trendingTweets.df$created)
class(trendingTweets.df$created)
save(trendingTweets.df, file = "trendingTweets202105.Rda")
# see how many missing values are there on a per column basis
sapply(trendingTweets.df, function(x) sum(is.na(x)))
# plot on tweets by time
ggplot(data = trendingTweets.df, aes(x = created)) +
geom_histogram(aes(fill = ..count..)) +
theme(legend.position = "none") +
xlab("Time") + ylab("Number of tweets") +
scale_fill_gradient(low = "midnightblue", high = "aquamarine4")
# plot tweets by source system (android, iphone, web, etc)
trendingTweets.df$tweetSource = sapply(trendingTweets.df$statusSource, encodeSource)
ggplot(trendingTweets.df[trendingTweets.df$tweetSource != 'others',], aes(tweetSource)) +
geom_bar(fill = "aquamarine4") +
theme(legend.position="none",
axis.title.x = element_blank(),
axis.text.x = element_text(angle = 45, hjust = 1)) +
ylab("Number of tweets") +
ggtitle("Tweets by Source")
namesCorpus <- Corpus(VectorSource(trendingTweets.df$screenName))  #using ScreenName
class(trendingTweets.df$screenName)
class(VectorSource(trendingTweets.df$screenName))
str(namesCorpus)
class(namesCorpus)
pal <- brewer.pal(9,"YlGnBu")
pal <- pal[-(1:4)]
set.seed(42)
wordcloud(words = namesCorpus, scale=c(3,0.5), max.words=100, random.order=FALSE,
rot.per=0.50, use.r.layout=TRUE, colors=pal)
wordcloud(words = namesCorpus, scale = c(3,0.5),
max.words = 300,
random.order = FALSE,
rot.per = 0.35,
use.r.layout = TRUE,
colors = pal,
)
wordcloud(words = namesCorpus, scale = c(3,0.5),
max.words = 100,
random.order = FALSE,
rot.per = 0.50,
use.r.layout = TRUE,
colors = pal,
)
wordcloud(words = namesCorpus, scale = c(3,0.5),
max.words = 100,
random.order = FALSE,
rot.per = 0.50,
use.r.layout = TRUE,
colors = pal,
)
#ts_plot
ts_plot(trendingTweets.df, "hours") +
labs(x = NULL, y = NULL,
title = "Frequency of tweets with a #Jihad hashtag",
subtitle = paste0(format(min(trendingTweets.df$created), "%d %B %Y"), " to ", format(max(trendingTweets.df$created),"%d %B %Y")),
caption = "Data collected from Twitter's REST API via rtweet") +
theme_minimal()
library (twitteR)
library (openssl)
library (NLP)
library (tm)
library (stringr)
library (dplyr)
library (ggplot2)
library(wordcloud)
library (rtweet)
library (tidytext)
library (tidyverse)
CONSUMER_SECRET <- "ZdGZi9aGG0VbOj1cdWXk6PzgQzmpAq7s3z9LsLUby2vGV7iHD7"
CONSUMER_KEY <- "ll18xpJcySQHXceY9oXO1cuZZ"
ACCESS_TOKEN <- "1533805509161017345-nT2JxCrqKUIplJXSrrdXDRoyG5grER"
ACCESS_SECRET <- "7EXHyEA844xyeCNfWgMd5ffoZGjfaWMmw1jw92VFSKAVN"
setup_twitter_oauth(
consumer_key = CONSUMER_KEY,
consumer_secret = CONSUMER_SECRET,
access_token = ACCESS_TOKEN,
access_secret = ACCESS_SECRET
)
trendingTweets = searchTwitter("#ResidentEvil4Remake -filter:retweets",
n =1000, lang = "en",
since = "2022-06-01",
until = "2022-06-18",
retryOnRateLimit = 120)
str (trendingTweets[[1]])
#perform a quick clean up
trendingTweets.df = twListToDF(trendingTweets)
trendingTweets.df$text <- sapply(trendingTweets.df$text,function(x) iconv(enc2utf8(x), sub="byte"))
class (trendingTweets.df)
names(trendingTweets.df)
head(trendingTweets.df$text)
#remove emoji
nohandles <- str_replace_all(trendingTweets.df$text, "@\\w+", " ")
nohandles$cleanedText <- gsub("http.*", " ", nohandles)
nohandles$cleanedText <- gsub("https.*", " ", nohandles$cleanedText )
head(nohandles$cleanedText) #dont include
nohandles$cleanedText <- str_replace_all(nohandles$cleanedText, "[^[:alnum:]]", " ")
nohandles$cleanedText <-  str_replace_all(nohandles$cleanedText,"[[^a-zA-Z0-9]]", " ")
head(nohandles$cleanedText)
#encoding a function to check for the source of the text
encodeSource <- function(x) {
if(grepl(">Twitter for iPhone</a>", x)){
"iphone"
}else if(grepl(">Twitter for iPad</a>", x)){
"ipad"
}else if(grepl(">Twitter for Android</a>", x)){
"android"
} else if(grepl(">Twitter Web Client</a>", x)){
"Web"
} else if(grepl(">Twitter for Windows Phone</a>", x)){
"windows phone"
}else if(grepl(">Facebook</a>", x)){ #This looks unreliable...
"facebook"
}else {
"others"
}
}
head (trendingTweets.df$text)
head (trendingTweets.df$created)
class (trendingTweets.df$created)
sapply(trendingTweets.df, function (x) sum (is.na(x)))
#plotiing the data on a frame
#plot on tweets by time/date
ggplot (data = trendingTweets.df, aes (x = created)) +
geom_histogram(aes(fill = ..count..)) +
theme(legend.position = "none") +
xlab ("Time") + ylab ("Number of tweets") +
scale_fill_gradient(low = "midnightblue", high = "aquamarine4")
trendingTweets.df$created[1:5]
#ts_plot
ts_plot(trendingTweets.df, "hours") +
labs(x = NULL, y = NULL,
title = "Frequency of tweets with a #Jihad hashtag",
subtitle = paste0(format(min(trendingTweets.df$created), "%d %B %Y"), " to ", format(max(trendingTweets.df$created),"%d %B %Y")),
caption = "Data collected from Twitter's REST API via rtweet") +
theme_minimal()
